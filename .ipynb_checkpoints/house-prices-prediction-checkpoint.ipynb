{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's import and put the train and test datasets in  pandas dataframe\n",
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5514d36634ed758df06c900533f84d15197bb5bf"
   },
   "outputs": [],
   "source": [
    "train.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8fb860edea37d05e02cfaac46b37da8ed7df05a8"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "223a0b591657b512c39c62d5b555bcba09e7643b"
   },
   "outputs": [],
   "source": [
    "plt.scatter(train.GrLivArea,train.SalePrice, c=\"blue\", marker = \"s\")\n",
    "plt.xlabel(\"GrLivArea\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "#Per check, 2 outliers which has greater living area but sold at very less price. Which needs to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4525e58c3489d1f3912502419f0ab215db00b7c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[train.GrLivArea < 4500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b99d5479c1ed250fc46a93d3e9ba00b63c9f72d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(train.LotArea,train.SalePrice, c=\"blue\", marker = \"s\")\n",
    "plt.xlabel(\"LotArea\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "#Similarly LotArea>150000 consider as outlier and remove from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68d85320f0ce7eacf135a04999e1e30f36a80078",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[train.LotArea < 150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1dc286a6f7c5618fd65d798bca29db267ec66e0f"
   },
   "outputs": [],
   "source": [
    "#Analysis on Target Variable\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "sns.distplot(train['SalePrice'], fit= norm);\n",
    "\n",
    "(mu, sigma) = norm.fit(train['SalePrice'])\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Per check SalePrice is highly right skewed with large kurtosis\n",
    "\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57dfa52331e0c0fe83ac591d80347ae6a6f51404"
   },
   "outputs": [],
   "source": [
    "#In order for better prediction, we need to fit the target variable into Normal Dist, hence we go for log transformation\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "sns.distplot(train['SalePrice'] , fit=norm);\n",
    "(mu, sigma) = norm.fit(train['SalePrice'])\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "#Now, the target variable is more or less similar to Norm Dist..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82d0a422c6e111029e7558ba3635bd0c327e1c2a"
   },
   "outputs": [],
   "source": [
    "#Data Cleaning Starts here\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "ytrain = train.SalePrice.values\n",
    "data = pd.concat((train, test)).reset_index(drop = True)\n",
    "data.drop(['SalePrice'], axis = 1, inplace = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f42a7e6b0a5dd8f9b823bb61092320f73e37ea45"
   },
   "outputs": [],
   "source": [
    "print((data.values == 'Abnorml').sum())\n",
    "col_idx = pd.np.argmax(data.values == 'Abnorml', axis=1).max()\n",
    "data.iloc[:, col_idx].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aeac00f70629b18f27a8a6956ab6580964aae311"
   },
   "outputs": [],
   "source": [
    "print((ytrain == 'Abnorml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "826fca16de3c103be2d8ef53e6b71d7594877e67"
   },
   "outputs": [],
   "source": [
    "missing = []\n",
    "for col in data:\n",
    "    count = data[col].isnull().sum(axis = 0)\n",
    "    if count:\n",
    "        missing.append(col)\n",
    "        print(\"%s : %d\" %(col, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f3d83308a6476deb5df03ded7e601684f891f95"
   },
   "outputs": [],
   "source": [
    "data_na = (data.isnull().sum() / len(data))*100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending = False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' : data_na})\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f92bc67020c4b09016ea9bca475a6759ddd78008"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15,12))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=data_na.index, y = data_na)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel(\"% of NAN Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db6141fd163c3fce7cffb21a9b8e18d66b259333"
   },
   "outputs": [],
   "source": [
    "corrmat = train.corr()\n",
    "corrmat.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "print(corrmat.SalePrice)\n",
    "plt.subplots(figsize=(15,12))\n",
    "sns.heatmap(corrmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c668212bd2d80125559921ab36b2fee9591bff0f"
   },
   "source": [
    "****Imputing Missed Values for each features one by one depending on their data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e3abab26c9d7152ce1784ae58bd7d81d031618c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PoolQC - Indicates houses with No POOL, hence for missing values we will fill with NONE\n",
    "data['PoolQC'] = data['PoolQC'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92695733b24e4230d11aab2fdb3a3c6448f440a7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MiscFeature - Similar to above no Miscellaneous Feature available for that house, hence fill NONE\n",
    "data['MiscFeature'] = data['MiscFeature'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f5c1186532320efc6beb81a8b21bbe9e09ae3b88",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Alley - NA means no Passage access\n",
    "data['Alley'] = data['Alley'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ced10ad891c80409adb775ce53b7e5d36d0bdb68",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fence - NA indicates no fence , hence NONE\n",
    "data['Fence'] = data['Fence'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0953b3891996c470c7515d6242d9701cfeeabbf0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FirePlaceQu - NA means no seperate FirePlace available, hence NONE\n",
    "data['FireplaceQu'] = data['FireplaceQu'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8b29c0ad9963a974e87df3ca9271ca7301fe3567",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Frontage is numerical data, it has high chance depend on neighbors area, hence we go for median imputation method\n",
    "data['LotFrontage'] = data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51ca6a762d49ef42746e826687da39204a01a9ce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replace NA with None since for categorical data\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    data[col] = data[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4055c277676629813906facdf6be54fa4d18d470",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    data[col] = data[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48e2b57511a55d3d0bb86de607822d7ea52fd50c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    data[col] = data[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d06a16d94ea3705b12e63282c57f3bf31cacb20a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NA most likely means no masonry veneer for these houses. We can fill 0 for the area and None for the type.\n",
    "data[\"MasVnrType\"] = data[\"MasVnrType\"].fillna(\"None\")\n",
    "data[\"MasVnrArea\"] = data[\"MasVnrArea\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3346e61087670feb8449c0ceb51cbee2d3c3730b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['MSZoning'] = data['MSZoning'].fillna(data['MSZoning'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b076764ae3d1ab714b24bd45e9fd872f5345985",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Utilities - This feature doesnt help in modelling, hence removed from data\n",
    "data = data.drop(['Utilities'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ccea5f42398f0e5ea5d173d7b5059980d7b8e78",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"Functional\"] = data[\"Functional\"].fillna(\"Typ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b8156936a1f3d43aeae014958da15867fa1411b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Electrical'] = data['Electrical'].fillna(data['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6ddb00c9d49c2518f1f36eec14c44486a1f3893",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['KitchenQual'] = data['KitchenQual'].fillna(data['KitchenQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce95e9e9794b81a78302a39319ab84d1ae6f5d71",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Exterior1st'] = data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\n",
    "data['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "563cb25517a5f0d0e9df04b47424bcc6b8dec5de",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['SaleType'] = data['SaleType'].fillna(data['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "802623a46b430dfc6c2fa1c3886cf0867ee7b592",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['MSSubClass'] = data['MSSubClass'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb6ef8d61c2683265d212bd763a9ffd97b6a8f39"
   },
   "outputs": [],
   "source": [
    "# Differentiate numerical features (minus the target) and categorical features\n",
    "categorical_features = train.select_dtypes(include = ['object']).columns\n",
    "numerical_features = train.select_dtypes(exclude = ['object']).columns\n",
    "print(\"Numerical features : \" + str(len(numerical_features)))\n",
    "print(\"Categorical features : \" + str(len(categorical_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5ec1eb22b80c27ebcf09da6aa4f484d47da087f"
   },
   "source": [
    "Transforming some numerical variables that are really categorical****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d456bf3563ae179aabdae34742b0e7d1adc9fbc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(data[c].values))\n",
    "    data[c] = lbl.transform(list(data[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb6ba4e5ed24c39ec56b6cbfceeb42d58b9dc07d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['TotalSF'] = data['TotalBsmtSF']+data['1stFlrSF']+data['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc14d31e79ae41ec4086fbcda4cb284756029ca6"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "data_numeric = data.dtypes[data.dtypes != 'object'].index\n",
    "data_skew = data[data_numeric].apply(lambda x: skew(x.dropna())).sort_values(ascending = False)\n",
    "\n",
    "skewness = pd.DataFrame({'Skew': data_skew})\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05d9eb79f89d088f6430162291688dee8c6bf73e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skewness = skewness[abs(skewness)>0.75]\n",
    "from scipy.special import boxcox1p\n",
    "skewness_features = skewness.index\n",
    "lam = 0.15\n",
    "for fld in skewness_features:\n",
    "  data[fld] = boxcox1p(data[fld], lam)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b898ea76d05a0704a7895245f2f9106a508b03e2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[:ntrain]\n",
    "test = data[:ntest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14e128348f2a6081971223e4a4e9e2ef67c72cd3"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df83f424e90a6450d24a5f13d253264e73980254",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric =  data.describe().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "492732a1784f02f6ed002277ca4f25f996b95bd9"
   },
   "source": [
    "****Modelling****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05b6f52ea3460d5fd318f2d1062a1b7c1f97dbc1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We will apply K-Fold Cross Validation for each training models\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "\n",
    "n_folds = 5\n",
    "def rmse_kfold(model):\n",
    "    kf = KFold(n_folds, shuffle = True, random_state = 42).get_n_splits(train.values)\n",
    "    rmse = np.sqrt(-cross_val_score(model, train[numeric].values, ytrain, scoring = \"neg_mean_squared_error\", cv = kf ))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d9a106007fdc41de372d3b86653364e92407ac6c"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC\n",
    "lm = linear_model.LinearRegression()\n",
    "score = rmse_kfold(lm)\n",
    "print('\\n OLS Score: {:.4f} ({:.4f})\\n'.format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "698c8f0dde2cee0c819bdf23f6ea12ba5cfbad01"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "score = rmse_kfold(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a4e5655d7027235f2c01d32961cb5c8229883a5"
   },
   "outputs": [],
   "source": [
    "enet = make_pipeline(RobustScaler(), ElasticNet(alpha = 0.0005, l1_ratio=.9,random_state = 1))\n",
    "score = rmse_kfold(enet)\n",
    "print(\"\\nElastic Net Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e9fdc8b8208db3f8361b048cebf482a9bef4431"
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "score = rmse_kfold(KRR)\n",
    "print(\"\\nKRR Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1844297112fe70ae95ff077c71a7b854937989fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "score = rmse_kfold(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ae066c29cbc3b7b3f85e053683a644ecd2cdaee"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "score = rmse_kfold(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "#Having issue with install xgboost package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dcc6b98a100077cd4a653cb825af47c4d3cdf4fb"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "score = rmse_kfold(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4cba946b55401f8a53e78dbe69719c78e51f2002"
   },
   "source": [
    "****Training & Prediction****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86e817362c4b26e52cb5e37060f3b96d8afd9f53",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e3076ba996fb7571bc1d8c8db0e7346fed78de9"
   },
   "outputs": [],
   "source": [
    "model_lgb.fit(train[numeric], ytrain)\n",
    "lgb_train_pred = model_lgb.predict(train[numeric])\n",
    "lgb_pred = np.expm1(model_lgb.predict(test[numeric].values))\n",
    "print(rmsle(ytrain, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96ce011cff450c1dd4f3864efaaac0c2052f4a48"
   },
   "source": [
    "**So, we achieved 7% error in testing data with Lgb Model fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c1b008e9a024e7680b17b6da128b899bc96cf39"
   },
   "outputs": [],
   "source": [
    "print(lgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "850210d2fbd72f32e193ab127a04ee075e1153cc",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
